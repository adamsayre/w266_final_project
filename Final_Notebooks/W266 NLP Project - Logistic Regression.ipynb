{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Project\n",
    "\n",
    "### Adam Sayre & Erin Werner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model (Baseline)\n",
    "\n",
    "Our goal is to build several machine learning model to help us classify which emotion the tweet represent. To start, we will build a logistic regression model to serve as our baseline. It is a simple yet powerful linear model that is a form of regression between 0 and 1 based on the input feature vector, which is useful in classification. This will then be compared to the more advanced methods involving BERT and neural networks.\n",
    "\n",
    "First, we will run the model on the dataset cleaned content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/erinwerner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/erinwerner/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd \n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import emoji\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import brown\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "assert(nltk.download(\"treebank\"))\n",
    "from nltk.corpus import europarl_raw\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras libraries\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#from tensorflow.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...  \n",
       "1                       i feel nor am i shamed by it  \n",
       "2  i had been feeling a little bit defeated by th...  \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...  \n",
       "4  i wouldnt feel burdened so that i would live m...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"~/Downloads/dataset(clean).csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>E_Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "      <td>rt usertaginstance usertaginstance oh fuck wro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>feel shamed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>feeling little bit defeated steps faith would ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "      <td>usertaginstance imagine reaction guy called jj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>wouldnt feel burdened would live life testamen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1       Emotion  \\\n",
       "0           0             0  disappointed   \n",
       "1           1             1  disappointed   \n",
       "2           2             2  disappointed   \n",
       "3           3             3         happy   \n",
       "4           4             4  disappointed   \n",
       "\n",
       "                                             Content  \\\n",
       "0  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  imagine if that reaction guy that called jj kf...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \\\n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                           E_Content  label  \n",
       "0  rt usertaginstance usertaginstance oh fuck wro...      0  \n",
       "1                                        feel shamed      0  \n",
       "2  feeling little bit defeated steps faith would ...      0  \n",
       "3  usertaginstance imagine reaction guy called jj...      1  \n",
       "4  wouldnt feel burdened would live life testamen...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e = pd.read_csv(\"~/Downloads/dataset(clean)_e.csv\") \n",
    "data_e.head()[['Emotion','Content','Original Content','E_Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>A_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "      <td>b rt davbingodav mcrackins oh fuck wrote fil g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>feel shamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>feeling little bit defeated steps faith would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "      <td>b ksiolajidebt imagine reaction guy called jj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>wouldnt feel burdened would live life testamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \\\n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                           A_Content  \n",
       "0  b rt davbingodav mcrackins oh fuck wrote fil g...  \n",
       "1                                        feel shamed  \n",
       "2  feeling little bit defeated steps faith would ...  \n",
       "3  b ksiolajidebt imagine reaction guy called jj ...  \n",
       "4  wouldnt feel burdened would live life testamen...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a = pd.read_csv(\"~/Downloads/dataset(clean)_a.csv\") \n",
    "data_a.head()[['Emotion','Content','Original Content','A_Content']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data.Emotion.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.Emotion.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(data.Content.values, data.label.values, test_size=0.3, \n",
    "                                                  random_state=42, stratify=data.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to vectorize our input sentences in order to perform the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<641602x137520 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7220343 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_c = CountVectorizer()\n",
    "vectorizer_c.fit(X_train_c)\n",
    "\n",
    "X_train_c = vectorizer_c.transform(X_train_c)\n",
    "X_val_c  = vectorizer_c.transform(X_val_c)\n",
    "X_train_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8948878617173323\n"
     ]
    }
   ],
   "source": [
    "classifier_c = LogisticRegression(max_iter = 1000)\n",
    "classifier_c.fit(X_train_c, y_train_c)\n",
    "score_c = classifier_c.score(X_val_c, y_val_c)\n",
    "\n",
    "print(\"Accuracy:\", score_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8953779925281025\n"
     ]
    }
   ],
   "source": [
    "y_pred_c = classifier_c.predict(X_val_c)\n",
    "f1_score_c = f1_score(y_val_c, y_pred_c, average='weighted')\n",
    "\n",
    "print(\"F1 Score:\", f1_score_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logistic regression model is 89% accurate, making it a good baseline model.\n",
    "\n",
    "#### Original Uncleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Original_Content\"] = data[\"Original Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oc, X_val_oc, y_train_oc, y_val_oc = train_test_split(data.Original_Content.values, data.label.values, \n",
    "                                                  test_size=0.3, random_state=42, stratify = data.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<641602x481718 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8042805 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_oc = CountVectorizer()\n",
    "vectorizer_oc.fit(X_train_oc)\n",
    "\n",
    "X_train_oc = vectorizer_oc.transform(X_train_oc)\n",
    "X_val_oc  = vectorizer_oc.transform(X_val_oc)\n",
    "X_train_oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9000338215024748\n"
     ]
    }
   ],
   "source": [
    "classifier_oc = LogisticRegression(max_iter = 1000)\n",
    "classifier_oc.fit(X_train_oc, y_train_oc)\n",
    "score_oc = classifier_oc.score(X_val_oc, y_val_oc)\n",
    "\n",
    "print(\"Accuracy:\", score_oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9004368911378267\n"
     ]
    }
   ],
   "source": [
    "y_pred_oc = classifier_oc.predict(X_val_oc)\n",
    "f1_score_oc = f1_score(y_val_oc, y_pred_oc, average='weighted')\n",
    "\n",
    "print(\"F1 Score:\", f1_score_oc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncleaned data actually recieved a better accuracy score of 90%. \n",
    "\n",
    "#### Custom Cleaned Data #1\n",
    "\n",
    "Now, we will run the same logistic regression model on our personally cleaned tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels_e = data_e.Emotion.unique()\n",
    "\n",
    "label_dict_e = {}\n",
    "for index, possible_label in enumerate(possible_labels_e):\n",
    "    label_dict_e[possible_label] = index\n",
    "label_dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e['label'] = data_e.Emotion.replace(label_dict_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e, X_val_e, y_train_e, y_val_e = train_test_split(data_e.E_Content.values, data_e.label.values, \n",
    "                                                  test_size=0.30,random_state=42, stratify=data_e.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<641602x248526 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5641629 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_e = CountVectorizer()\n",
    "vectorizer_e.fit(X_train_e)\n",
    "\n",
    "X_train_e = vectorizer_e.transform(X_train_e)\n",
    "X_val_e  = vectorizer_e.transform(X_val_e)\n",
    "X_train_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894051415957203\n"
     ]
    }
   ],
   "source": [
    "classifier_e = LogisticRegression(max_iter = 1000)\n",
    "classifier_e.fit(X_train_e, y_train_e)\n",
    "score_e = classifier_e.score(X_val_e, y_val_e)\n",
    "\n",
    "print(\"Accuracy:\", score_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8944883271846511\n"
     ]
    }
   ],
   "source": [
    "y_pred_e = classifier_e.predict(X_val_e)\n",
    "f1_score_e = f1_score(y_val_e, y_pred_e, average='weighted')\n",
    "\n",
    "print(\"F1 Score:\", f1_score_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our personal cleaning method performed roughly the same as the original cleaned dataset.\n",
    "\n",
    "#### Custom Cleaned Data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some starting variables\n",
    "vocab_size = 10000\n",
    "max_length = 40\n",
    "\n",
    "X = data['Original Content'].to_numpy()\n",
    "y = data.Emotion.to_numpy()\n",
    "\n",
    "# First split the data into train and test\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# Next split the train data into train and dev data\n",
    "X_train_a, X_dev_a, y_train_a, y_dev_a = train_test_split(X_train_a, y_train_a, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "tk = Tokenizer(num_words = vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower=True, split = \" \")\n",
    "tk.fit_on_texts(X_train_a)\n",
    "\n",
    "X_train_seq = tk.texts_to_sequences(X_train_a)\n",
    "X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=max_length)\n",
    "\n",
    "X_dev_seq = tk.texts_to_sequences(X_dev_a)\n",
    "X_dev_seq_trunc = pad_sequences(X_dev_seq, maxlen=max_length)\n",
    "\n",
    "X_test_seq = tk.texts_to_sequences(X_test_a)\n",
    "X_test_seq_trunc = pad_sequences(X_test_seq, maxlen=max_length)\n",
    "\n",
    "# Encoding output variable\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_le = le.fit_transform(y_train_a)\n",
    "y_train_emb = to_categorical(y_train_le)\n",
    "\n",
    "y_dev_le = le.transform(y_dev_a)\n",
    "y_dev_emb = to_categorical(y_dev_le)\n",
    "\n",
    "y_test_le = le.transform(y_test_a)\n",
    "y_test_emb = to_categorical(y_test_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these for training!\n",
    "X_train_final_a = X_train_seq_trunc\n",
    "X_dev_final_a = X_dev_seq_trunc\n",
    "X_test_final_a = X_test_seq_trunc\n",
    "\n",
    "y_train_final_a = y_train_emb\n",
    "y_dev_final_a = y_dev_emb\n",
    "y_test_final_a = y_test_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from dataframe\n",
    "possible_labels_a = data_a.Emotion.unique()\n",
    "\n",
    "label_dict_a = {}\n",
    "for index, possible_label in enumerate(possible_labels_a):\n",
    "    label_dict_a[possible_label] = index\n",
    "label_dict_a\n",
    "data_a['label'] = data_a.Emotion.replace(label_dict_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(data_a.A_Content.values, data_a.label.values, \n",
    "                                                  test_size=0.30,random_state=42, stratify=data_a.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<641602x453777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5790974 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_a = CountVectorizer()\n",
    "vectorizer_a.fit(X_train_a)\n",
    "\n",
    "X_train_a = vectorizer_a.transform(X_train_a)\n",
    "X_val_a  = vectorizer_a.transform(X_val_a)\n",
    "X_train_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896160713961007\n"
     ]
    }
   ],
   "source": [
    "classifier_a = LogisticRegression(max_iter = 1000)\n",
    "classifier_a.fit(X_train_a, y_train_a)\n",
    "score_a = classifier_a.score(X_val_a, y_val_a)\n",
    "\n",
    "print(\"Accuracy:\", score_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8965497764630669\n"
     ]
    }
   ],
   "source": [
    "y_pred_a = classifier_a.predict(X_val_a)\n",
    "f1_score_a = f1_score(y_val_a, y_pred_a, average='weighted')\n",
    "\n",
    "print(\"F1 Score:\", f1_score_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our other personal cleaning method performed roughly the same as the original cleaned dataset.\n",
    "\n",
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaning Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orig. Uncleaned</td>\n",
       "      <td>0.900034</td>\n",
       "      <td>0.900437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orig. Cleaned</td>\n",
       "      <td>0.894888</td>\n",
       "      <td>0.895378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Custom Cleaned #1</td>\n",
       "      <td>0.894051</td>\n",
       "      <td>0.894488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Custom Cleaned #2</td>\n",
       "      <td>0.896161</td>\n",
       "      <td>0.896550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cleaning Method  Accuracy  F1 Score\n",
       "0    Orig. Uncleaned  0.900034  0.900437\n",
       "1      Orig. Cleaned  0.894888  0.895378\n",
       "2  Custom Cleaned #1  0.894051  0.894488\n",
       "3  Custom Cleaned #2  0.896161  0.896550"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_acc = [score_oc, score_c, score_e, score_a]\n",
    "lr_f1 = [f1_score_oc, f1_score_c, f1_score_e, f1_score_a]\n",
    "lr_values = ['Orig. Uncleaned', 'Orig. Cleaned', 'Custom Cleaned #1', 'Custom Cleaned #2']\n",
    "lr_df = pd.DataFrame()\n",
    "lr_df['Cleaning Method'] = lr_values\n",
    "lr_df['Accuracy'] = lr_acc\n",
    "lr_df['F1 Score'] = lr_f1\n",
    "lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
