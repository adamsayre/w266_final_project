{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Project\n",
    "\n",
    "### Adam Sayre & Erin Werner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/erinwerner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/erinwerner/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd \n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import emoji\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import brown\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "assert(nltk.download(\"treebank\"))\n",
    "from nltk.corpus import europarl_raw\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras libraries\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#from tensorflow.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...  \n",
       "1                       i feel nor am i shamed by it  \n",
       "2  i had been feeling a little bit defeated by th...  \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...  \n",
       "4  i wouldnt feel burdened so that i would live m...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"~/Downloads/dataset(clean).csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>E_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "      <td>rt usertaginstance usertaginstance oh fuck wro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>feel shamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>feeling little bit defeated steps faith would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "      <td>usertaginstance imagine reaction guy called jj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>wouldnt feel burdened would live life testamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \\\n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                           E_Content  \n",
       "0  rt usertaginstance usertaginstance oh fuck wro...  \n",
       "1                                        feel shamed  \n",
       "2  feeling little bit defeated steps faith would ...  \n",
       "3  usertaginstance imagine reaction guy called jj...  \n",
       "4  wouldnt feel burdened would live life testamen...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e = pd.read_csv(\"~/Downloads/dataset(clean)_e.csv\") \n",
    "data_e.head()[['Emotion','Content','Original Content','E_Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>A_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "      <td>b rt davbingodav mcrackins oh fuck wrote fil g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>feel shamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>feeling little bit defeated steps faith would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "      <td>b ksiolajidebt imagine reaction guy called jj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>wouldnt feel burdened would live life testamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \\\n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                           A_Content  \n",
       "0  b rt davbingodav mcrackins oh fuck wrote fil g...  \n",
       "1                                        feel shamed  \n",
       "2  feeling little bit defeated steps faith would ...  \n",
       "3  b ksiolajidebt imagine reaction guy called jj ...  \n",
       "4  wouldnt feel burdened would live life testamen...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a = pd.read_csv(\"~/Downloads/dataset(clean)_a.csv\") \n",
    "data_a.head()[['Emotion','Content','Original Content','A_Content']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build the model, then pass each of our various cleaning methods through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some starting variables\n",
    "vocab_size = 10000\n",
    "max_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = models.Sequential()\n",
    "emb_model.add(layers.Embedding(vocab_size, 8, input_length=max_length, embeddings_regularizer='l1'))\n",
    "emb_model.add(layers.Flatten())\n",
    "emb_model.add(layers.Dense(3, activation='relu'))\n",
    "emb_model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 963       \n",
      "=================================================================\n",
      "Total params: 80,963\n",
      "Trainable params: 80,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data.Emotion.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.Emotion.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(data.Content.values, data.label.values, test_size=0.3, \n",
    "                                                  random_state=42, stratify=data.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_c = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower=True, split = \" \")\n",
    "tokenizer_c.fit_on_texts(X_train_c)\n",
    "\n",
    "X_train_seq_c = tokenizer_c.texts_to_sequences(X_train_c)\n",
    "X_train_seq_trunc_c = pad_sequences(X_train_seq_c, maxlen=max_length)\n",
    "\n",
    "X_val_seq_c = tokenizer_c.texts_to_sequences(X_val_c)\n",
    "X_val_seq_trunc_c = pad_sequences(X_val_seq_c, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding output variable\n",
    "le_c = LabelEncoder()\n",
    "\n",
    "y_train_le_c = le_c.fit_transform(y_train_c)\n",
    "y_train_emb_c = to_categorical(y_train_le_c)\n",
    "\n",
    "y_val_le_c = le_c.transform(y_val_c)\n",
    "y_val_emb_c = to_categorical(y_val_le_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20051/20051 [==============================] - 17s 805us/step - loss: nan - accuracy: 0.3420\n",
      "Epoch 2/5\n",
      "20051/20051 [==============================] - 16s 775us/step - loss: nan - accuracy: 0.3420\n",
      "Epoch 3/5\n",
      "20051/20051 [==============================] - 16s 777us/step - loss: nan - accuracy: 0.3425\n",
      "Epoch 4/5\n",
      "20051/20051 [==============================] - 16s 790us/step - loss: nan - accuracy: 0.3419\n",
      "Epoch 5/5\n",
      "20051/20051 [==============================] - 16s 782us/step - loss: nan - accuracy: 0.3421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f977a93c250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.reset_states()\n",
    "emb_model.fit(X_train_seq_trunc_c, y_train_emb_c, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3423\n",
      "Validation Accuracy:  0.3423\n"
     ]
    }
   ],
   "source": [
    "percp_loss_c, percp_accuracy_c = emb_model.evaluate(X_train_seq_trunc_c, y_train_emb_c, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(percp_accuracy_c))\n",
    "percp_loss_c_val, percp_accuracy_c_val = emb_model.evaluate(X_val_seq_trunc_c, y_val_emb_c, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(percp_accuracy_c_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Uncleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Original_Content\"] = data[\"Original Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oc, X_val_oc, y_train_oc, y_val_oc = train_test_split(data.Original_Content.values, data.label.values, \n",
    "                                                  test_size=0.3, random_state=42, stratify = data.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_oc = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower=True, split = \" \")\n",
    "tokenizer_oc.fit_on_texts(X_train_oc)\n",
    "\n",
    "X_train_seq_oc = tokenizer_oc.texts_to_sequences(X_train_oc)\n",
    "X_train_seq_trunc_oc = pad_sequences(X_train_seq_oc, maxlen=max_length)\n",
    "\n",
    "X_val_seq_oc = tokenizer_oc.texts_to_sequences(X_val_oc)\n",
    "X_val_seq_trunc_oc = pad_sequences(X_val_seq_oc, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding output variable\n",
    "le_oc = LabelEncoder()\n",
    "\n",
    "y_train_le_oc = le_oc.fit_transform(y_train_oc)\n",
    "y_train_emb_oc = to_categorical(y_train_le_oc)\n",
    "\n",
    "y_val_le_oc = le_oc.transform(y_val_oc)\n",
    "y_val_emb_oc = to_categorical(y_val_le_oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20051/20051 [==============================] - 16s 802us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 2/5\n",
      "20051/20051 [==============================] - 16s 795us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 3/5\n",
      "20051/20051 [==============================] - 15s 752us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 4/5\n",
      "20051/20051 [==============================] - 15s 766us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 5/5\n",
      "20051/20051 [==============================] - 15s 761us/step - loss: nan - accuracy: 0.3423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f970a896e80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.reset_states()\n",
    "emb_model.fit(X_train_seq_trunc_oc, y_train_emb_oc, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3423\n",
      "Validation Accuracy:  0.3423\n"
     ]
    }
   ],
   "source": [
    "percp_loss_oc, percp_accuracy_oc = emb_model.evaluate(X_train_seq_trunc_oc, y_train_emb_oc, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(percp_accuracy_oc))\n",
    "percp_loss_oc_val, percp_accuracy_oc_val = emb_model.evaluate(X_val_seq_trunc_oc, y_val_emb_oc, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(percp_accuracy_oc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Cleaned Data #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels_e = data_e.Emotion.unique()\n",
    "\n",
    "label_dict_e = {}\n",
    "for index, possible_label in enumerate(possible_labels_e):\n",
    "    label_dict_e[possible_label] = index\n",
    "label_dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e['label'] = data_e.Emotion.replace(label_dict_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e, X_val_e, y_train_e, y_val_e = train_test_split(data_e.E_Content.values, data_e.label.values, \n",
    "                                                  test_size=0.30,random_state=42, stratify=data_e.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_e = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower=True, split = \" \")\n",
    "tokenizer_e.fit_on_texts(X_train_e)\n",
    "\n",
    "X_train_seq_e = tokenizer_e.texts_to_sequences(X_train_e)\n",
    "X_train_seq_trunc_e = pad_sequences(X_train_seq_e, maxlen=max_length)\n",
    "\n",
    "X_val_seq_e = tokenizer_e.texts_to_sequences(X_val_e)\n",
    "X_val_seq_trunc_e = pad_sequences(X_val_seq_e, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding output variable\n",
    "le_e = LabelEncoder()\n",
    "\n",
    "y_train_le_e = le_e.fit_transform(y_train_e)\n",
    "y_train_emb_e = to_categorical(y_train_le_e)\n",
    "\n",
    "y_val_le_e = le_e.transform(y_val_e)\n",
    "y_val_emb_e = to_categorical(y_val_le_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20051/20051 [==============================] - 16s 797us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 2/5\n",
      "20051/20051 [==============================] - 16s 776us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 3/5\n",
      "20051/20051 [==============================] - 16s 786us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 4/5\n",
      "20051/20051 [==============================] - 15s 766us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 5/5\n",
      "20051/20051 [==============================] - 15s 758us/step - loss: nan - accuracy: 0.3423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96c445a430>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.reset_states()\n",
    "emb_model.fit(X_train_seq_trunc_e, y_train_emb_e, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3423\n",
      "Validation Accuracy:  0.3423\n"
     ]
    }
   ],
   "source": [
    "percp_loss_e, percp_accuracy_e = emb_model.evaluate(X_train_seq_trunc_e, y_train_emb_e, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(percp_accuracy_e))\n",
    "percp_loss_e_val, percp_accuracy_e_val = emb_model.evaluate(X_val_seq_trunc_e, y_val_emb_e, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(percp_accuracy_e_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Cleaned Data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from dataframe\n",
    "possible_labels_a = data_a.Emotion.unique()\n",
    "\n",
    "label_dict_a = {}\n",
    "for index, possible_label in enumerate(possible_labels_a):\n",
    "    label_dict_a[possible_label] = index\n",
    "label_dict_a\n",
    "data_a['label'] = data_a.Emotion.replace(label_dict_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(data_a.A_Content.values, data_a.label.values, \n",
    "                                                  test_size=0.30,random_state=42, stratify=data_a.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_a = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower=True, split = \" \")\n",
    "tokenizer_a.fit_on_texts(X_train_a)\n",
    "\n",
    "X_train_seq_a = tokenizer_a.texts_to_sequences(X_train_a)\n",
    "X_train_seq_trunc_a = pad_sequences(X_train_seq_a, maxlen=max_length)\n",
    "\n",
    "X_val_seq_a = tokenizer_a.texts_to_sequences(X_val_a)\n",
    "X_val_seq_trunc_a = pad_sequences(X_val_seq_a, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding output variable\n",
    "le_a = LabelEncoder()\n",
    "\n",
    "y_train_le_a = le_a.fit_transform(y_train_a)\n",
    "y_train_emb_a = to_categorical(y_train_le_a)\n",
    "\n",
    "y_val_le_a = le_e.transform(y_val_a)\n",
    "y_val_emb_a = to_categorical(y_val_le_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20051/20051 [==============================] - 16s 804us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 2/5\n",
      "20051/20051 [==============================] - 16s 781us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 3/5\n",
      "20051/20051 [==============================] - 16s 779us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 4/5\n",
      "20051/20051 [==============================] - 15s 762us/step - loss: nan - accuracy: 0.3423\n",
      "Epoch 5/5\n",
      "20051/20051 [==============================] - 15s 759us/step - loss: nan - accuracy: 0.3423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f970a88e4c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.reset_states()\n",
    "emb_model.fit(X_train_seq_trunc_a, y_train_emb_a, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3423\n",
      "Validation Accuracy:  0.3423\n"
     ]
    }
   ],
   "source": [
    "percp_loss_a, percp_accuracy_a = emb_model.evaluate(X_train_seq_trunc_a, y_train_emb_a, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(percp_accuracy_a))\n",
    "percp_loss_a_val, percp_accuracy_a_val = emb_model.evaluate(X_val_seq_trunc_a, y_val_emb_a, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(percp_accuracy_a_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaning Method</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orig. Uncleaned</td>\n",
       "      <td>0.342268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orig. Cleaned</td>\n",
       "      <td>0.342268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Custom Cleaned #1</td>\n",
       "      <td>0.342268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Custom Cleaned #2</td>\n",
       "      <td>0.342268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cleaning Method  F1 Score\n",
       "0    Orig. Uncleaned  0.342268\n",
       "1      Orig. Cleaned  0.342268\n",
       "2  Custom Cleaned #1  0.342268\n",
       "3  Custom Cleaned #2  0.342268"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_acc = [percp_accuracy_oc, percp_accuracy_c, percp_accuracy_e, percp_accuracy_a]\n",
    "#p_loss = [percp_loss_oc, percp_loss_c, percp_loss_e, percp_loss_a]\n",
    "p_values = ['Orig. Uncleaned', 'Orig. Cleaned', 'Custom Cleaned #1', 'Custom Cleaned #2']\n",
    "p_df = pd.DataFrame()\n",
    "p_df['Cleaning Method'] = p_values\n",
    "p_df['F1 Score'] = p_acc\n",
    "#p_df['Loss'] = p_loss\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
