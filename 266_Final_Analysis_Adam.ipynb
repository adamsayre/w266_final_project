{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Analysis - W266 Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a few python packages using pip\n",
    "from w266_common import utils\n",
    "utils.require_package(\"wget\")      # for fetching dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "# NLTK for NLP utils\n",
    "import nltk\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary, tf_embed_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras libraries\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...  \n",
       "1                       i feel nor am i shamed by it  \n",
       "2  i had been feeling a little bit defeated by th...  \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...  \n",
       "4  i wouldnt feel burdened so that i would live m...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweet_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Content.to_numpy()\n",
    "y = df.Emotion.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(916575,)\n",
      "(916575,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some starting variables\n",
    "vocab_size = 10000\n",
    "max_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# Next split the train data into train and dev data\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (552694,)\n",
      "Dev data shape:    (272223,)\n",
      "Test data shape:   (91658,)\n",
      "Train Label shape: (552694,)\n",
      "Dev label shape:   (272223,)\n",
      "Test label shape:  (91658,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape:  {}\".format(X_train.shape))\n",
    "print(\"Dev data shape:    {}\".format(X_dev.shape))\n",
    "print(\"Test data shape:   {}\".format(X_test.shape))\n",
    "print(\"Train Label shape: {}\".format(y_train.shape))\n",
    "print(\"Dev label shape:   {}\".format(y_dev.shape))\n",
    "print(\"Test label shape:  {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron\n",
    "\n",
    "First, word embeddings. Will use default keras embeddings, i guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "tk = Tokenizer(num_words = vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n', lower=True, split = \" \")\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=max_length)\n",
    "\n",
    "X_dev_seq = tk.texts_to_sequences(X_dev)\n",
    "X_dev_seq_trunc = pad_sequences(X_dev_seq, maxlen=max_length)\n",
    "\n",
    "# Encoding output variable\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_train_emb = to_categorical(y_train_le)\n",
    "\n",
    "y_dev_le = le.transform(y_dev)\n",
    "y_dev_emb = to_categorical(y_dev_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = models.Sequential()\n",
    "emb_model.add(layers.Embedding(vocab_size, 8, input_length=max_length, embeddings_regularizer='l1'))\n",
    "emb_model.add(layers.Flatten())\n",
    "emb_model.add(layers.Dense(3, activation='relu'))\n",
    "emb_model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 963       \n",
      "=================================================================\n",
      "Total params: 80,963\n",
      "Trainable params: 80,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17272/17272 [==============================] - 15s 831us/step - loss: nan - accuracy: 0.3286\n",
      "Epoch 2/10\n",
      "17272/17272 [==============================] - 14s 832us/step - loss: nan - accuracy: 0.3272\n",
      "Epoch 3/10\n",
      "17272/17272 [==============================] - 15s 850us/step - loss: nan - accuracy: 0.3285\n",
      "Epoch 4/10\n",
      "17272/17272 [==============================] - 15s 843us/step - loss: nan - accuracy: 0.3277\n",
      "Epoch 5/10\n",
      "17272/17272 [==============================] - 14s 835us/step - loss: nan - accuracy: 0.3292\n",
      "Epoch 6/10\n",
      "17272/17272 [==============================] - 14s 833us/step - loss: nan - accuracy: 0.3287\n",
      "Epoch 7/10\n",
      "17272/17272 [==============================] - 14s 819us/step - loss: nan - accuracy: 0.3288\n",
      "Epoch 8/10\n",
      "17272/17272 [==============================] - 14s 822us/step - loss: nan - accuracy: 0.32731s -\n",
      "Epoch 9/10\n",
      "17272/17272 [==============================] - 14s 835us/step - loss: nan - accuracy: 0.3275\n",
      "Epoch 10/10\n",
      "17272/17272 [==============================] - 14s 816us/step - loss: nan - accuracy: 0.3268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x157b8da0f88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.reset_states()\n",
    "emb_model.fit(X_train_seq_trunc, y_train_emb, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8507/8507 [==============================] - 4s 456us/step - loss: nan - accuracy: 0.3287\n",
      "test loss, test acc: [nan, 0.32867172360420227]\n"
     ]
    }
   ],
   "source": [
    "results = emb_model.evaluate(X_dev_seq_trunc, y_dev_emb)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
